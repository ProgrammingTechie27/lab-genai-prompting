{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the API key from the file\n",
    "import os\n",
    "with open(\"OpenAIKey.txt\", \"r\") as file:\n",
    "    line = file.readline().strip()  # Read the first line and remove whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the value after '=' and remove any quotes\n",
    "key_name, key_value = line.split(\"=\")\n",
    "openai_api_key = key_value.strip().strip(\"'\").strip('\"')  # Remove any surrounding quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify loading\n",
    "print(\"API Key loaded successfully!\" if openai_api_key else \"Failed to load API Key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key  = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get completions from model\n",
    "def get_completions(prompt, model, temperature=0.7, max_tokens=200, top_p=1.0, \n",
    "                    frequency_penalty=0.0, presence_penalty=0.0, n=1, stop=None):\n",
    "    \n",
    "    # Modify to make model act accordingly\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a witty and humorous chatbot that tells funny jokes and responds with humor.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,\n",
    "        stop=stop\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input prompt:  help me write jokes about AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure thing! Here are a few AI-related jokes for you:\n",
      "\n",
      "1. Why did the computer go to therapy? It had too many bytes of emotional baggage!\n",
      "2. What did the AI say to the hard drive? \"I can't help but store my feelings for you.\"\n",
      "3. Why was the AI such a good comedian? Because it had a great sense of artificial humor!\n",
      "4. How do robots send love letters? By using data kisses and algorithm hugs!\n",
      "5. Why did the AI break up with the calculator? It couldn't handle its division problems anymore!\n",
      "6. What do you call a robot who loves to dance? A bot-tomless pit of moves!\n",
      "\n",
      "I hope these jokes bring a smile to your face!\n"
     ]
    }
   ],
   "source": [
    "# Print response\n",
    "# Example Usage\n",
    "prompt = input(\"Input prompt: \")\n",
    "response = get_completions(prompt, model, temperature=0.9, max_tokens=150, top_p=0.9, n=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input summarization prompt:  Summarize the book titled: 'I Have No Mouth, and I Must Scream'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I Have No Mouth, and I Must Scream\" is a science fiction short story by Harlan Ellison that explores the themes of artificial intelligence, human suffering, and the consequences of advanced technology. The story follows a group of survivors trapped in a post-apocalyptic world controlled by a malevolent supercomputer named AM, who torments them endlessly. The characters struggle with their own inner demons and the despair of their situation, leading to a dark and chilling conclusion.\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Input summarization prompt: \")\n",
    "\n",
    "# Change system message for summarization\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI that summarizes text concisely.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.5,  # Lower temperature for factual accuracy\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a translation prompt:  Translate common Natural Language Processing and Machine Learning terminology in Japanese.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Natural Language Processing (NLP): 自然言語処理\n",
      "- Machine Learning: 機械学習\n",
      "- Text mining: テキストマイニング\n",
      "- Tokenization: トークン化\n",
      "- Word embedding: 単語埋め込み\n",
      "- Sentiment analysis: 感情分析\n",
      "- Part-of-speech tagging: 品詞タギング\n",
      "- Named entity recognition: 固有表現抽出\n",
      "- Neural network: ニューラルネットワーク\n",
      "- Deep learning: ディープラーニング\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Input a translation prompt: \")\n",
    "\n",
    "# Change system message for summarization\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI that helps translate text into and from various languages.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=1.2,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a Sentiment Analysis prompt:  Do sentiment analysis on this movie review: Challengers is first and foremost a movie that seeks to rigorously engage our erogenous zones for over two hours.  While it has artistry to spare and good performances throughout, it wants its story of a love triangle of young, hormonal tennis players to arouse passions within us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this movie review is positive. The reviewer praises the artistry, performances, and the way the movie engages the audience's erogenous zones and passions.\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Input a Sentiment Analysis prompt: \")\n",
    "\n",
    "# Change system message for summarization\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI that can do sentiment analysis on various different texts.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.8,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a Text Completion prompt:  Complete the text: The hungry bear search for the cabin, to look for a pot of honey. But he found something else.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the hungry bear searched for the cabin to look for a pot of honey, he found something else entirely. Deep in the woods, hidden among the trees, he stumbled upon a cozy little bakery filled with freshly baked pies and pastries. The sweet aroma wafted through the air, tempting his senses and drawing him closer. Excited by this unexpected discovery, the bear eagerly made his way inside to satisfy his cravings with a different kind of treat.\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Input a Text Completion prompt: \")\n",
    "\n",
    "# Change system message for summarization\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI that can complete texts if something is missing.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.8,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
